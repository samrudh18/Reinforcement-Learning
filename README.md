# CS698R-Deep-Reinforcement-Learning

This repository contains the implementation and analysis of multiple Reinforcement Learning based algorithms. The repository contains three types of documents: **Questions**, **Solutions** and **Jupyter Notebooks**, segregated in three folders: **Assignment-1**, **Midsem** and **Assignment-3**. The algorithms and environments have been implemented in Python using the following libraries: Numpy, Matplotlib, Pandas, Copy, Gym and PyTorch (Deep RL). All of the above was done as a part of the CS698R-Deep Reinforcement Learning course instructed by Prof Ashutosh Modi at IIT Kanpur (Fall-2021). 

## [Assignment-1](/Assignment-1)

Contains the implementation and analysis of:  
  
a) Environments  
&emsp;	i) Two-Armed Bernoulli Bandit  
&emsp;	ii) 10-Armed Gaussian Bandit  
&emsp;	iii) Random walk environment  
a) Strategies  
&emsp;	i) Pure Exploitation (Greedy) strategy  
&emsp;	ii) Pure Exploration strategy  
&emsp;	iii) epsilon-Greedy strategy  
&emsp;	iv) Decaying epsilon-Greedy strategy  
&emsp;	v) Softmax  
&emsp;	vi) UCB  
&emsp;	vii) Monte Carlo - FVMC  
&emsp;	viii) Monte Carlo - EVMC  
&emsp;	ix) Temporal Difference Learning  
c) Comparison of strategies (Two and Ten-armed Bandit environments)  
&emsp;	i) Performance  
&emsp;	ii) Regret  
&emsp;	iii) Percentage optimal action  

## [Midsem](/Midsem)

Contains the implementation and analysis of: 

a) Environment  
&emsp;	i) Random Maze Environment  
b) Strategies  
&emsp;	i) RME Optimal Policy via Dynamic Programming  
&emsp;	ii) RME Prediction with MDP Unknown  
&emsp;	iii) Monte-Carlo Estimation  
&emsp;	iv) Temporal Difference Prediction  
&emsp;	v) n-step TD  
&emsp;	vi) Temporal Difference Lambda  
c) Comparison of strategies  
&emsp;	i) Averaged value approximations over time  
&emsp;	ii) Target Sequence  

## [Assignment-3](/Assignment-3)

Contains the implementation and analysis of:  

a) Environments (imported from OpenAI Gym)  
&emsp;	i) CartPole  
&emsp;	ii) Mountain Car  
b) Agents  
&emsp;	i) Neural Fitted Q (NFQ)  
&emsp;	ii) Deep Q-Network (DQN)  
&emsp;	iii) Double DQN (DDQN)  
&emsp;	iv) Duelling DDQN  
&emsp;	v) Duelling Double Deep Q Network with Prioritized Experience Replay (D3QN-PER)  
c) Training   
&emsp;	i) Training on CartPole  
&emsp;	ii) Training on Mountain Car  









